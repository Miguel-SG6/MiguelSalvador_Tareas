Hadoop se formo en 2004 cuando Doug Cutting un ingeniero que en trabajaba en Google utilizo ciertas técnicas para manejar volúmenes grandes de datos, haciéndolos mas pequeños para poder ser utilizados. Doug Cutting se cambio a Yahoo y ahí siguió investigando hasta que logro terminar de desarrollar la plataforma en 2008. 
La plataforma es Open Source consta de de un sistema para almacenar información en el que ésta se replica en varias máquinas, distribuyéndose de tal manera que si una máquina se cae no se pierdan los datos. Si es necesario añadir más información se añaden más servidores sin que haya problemas de compatibilidad o reorganización de los datos.
Este sistema que se basa en dos grandes partes, los archivos HDFS y el sistema MapReduce. Sin embargo, también contiene varias herramientas tales como Eclipse, Sqoop,Flume,Hive,Pig,Hbase,Oozie, Zookeeper y Mahout.
La escalabilidad y disponibilidad son otras de sus claves, gracias a la replicación de los datos y tolerancia a los fallos. Los elementos importantes del cluster son NameNode( Regula el acceso a los ficheros por parte de los clientes.),DataNode(Son los responsables de leer y escribir las peticiones de los clientes) y MapReduce(Es un proceso batch, creado para el proceso distribuido de los datos. Permite de una forma simple, paralelizar trabajo sobre los grandes volúmenes de datos).
Una de las cosas que me pareció curiosa a la hora de leer la historio fue como surgió el nombre y logo de este software ya que Doug Cautting tenia un hijo y el niño tienia un elefante peluche al cual le llamaba hadoop y asi fue como Cutting decidió bautizar  a este software que también tomaría de ahí su logo, un elefante amarillo.